{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uyVgEo3qOeAB"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eliane-orlandin/Trilha_para_elas_IA/blob/main/C%C3%B3pia_de_Aula_guiada_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O que vamos aprender?\n",
        "\n",
        "* Carregar um modelo de linguagem em memória\n",
        "* Configurando o Hardware (CPU vs GPU)\n",
        "* Controlando a variabilidade da resposta com o parâmetro Temperature\n",
        "* Interagindo com o Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "ThwthvzbON0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ZsejGb06NSCb",
        "outputId": "93478f9f-a4f3-462f-f9cc-4a3d12f4843c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação das bibliotecas"
      ],
      "metadata": {
        "id": "uyVgEo3qOeAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip datasets"
      ],
      "metadata": {
        "id": "oo5m0cyecNq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando o modelo em memória\n",
        "**Pipeline**\n",
        "https://huggingface.co/docs/transformers/en/main_classes/pipelines\n"
      ],
      "metadata": {
        "id": "mp64UNQT8hjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ">"
      ],
      "metadata": {
        "id": "bjdi4a5jkLKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-generation\", model=\"unsloth/Llama-3.2-1B-Instruct\")\n"
      ],
      "metadata": {
        "id": "C_AyQidyhmul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Olá, tudo bem?\"},\n",
        "]\n",
        "pipe(messages)"
      ],
      "metadata": {
        "id": "cLJidvctnTFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4nKkEcBzuX_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Controlando a variabilidade da resposta com o parâmetro: Temperature\n",
        "\n",
        ">[Configurações para a geração do texto](https://huggingface.co/docs/transformers/v4.52.3/en/main_classes/text_generation#transformers.GenerationConfig)\n",
        "\n",
        "<img src=https://res.cloudinary.com/dwppkb069/image/upload/v1683736290/tips/images-03-temperature.mp4/03-temperature_30_03-25000-if-temperature-is-like-almost-0--were-going-to-have-a-very-sharp-peaked-distribution_wprxqo.png width=\"500\">"
      ],
      "metadata": {
        "id": "lHVxJPY3i1cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Me conte uma boa piada\"},\n",
        "]\n",
        "pipe(messages)[0][\"generated_text\"][1]['content']"
      ],
      "metadata": {
        "id": "N8sEX58oi4tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Me conte uma boa piada\"},\n",
        "]\n",
        "pipe(messages, temperature=0.01)[0][\"generated_text\"][1]['content']"
      ],
      "metadata": {
        "id": "E8VsbUAVqLje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregar dataset :: b2w-reviews01"
      ],
      "metadata": {
        "id": "SLIa6P_IOn_W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VlkFWc7cGN2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"ruanchaves/b2w-reviews01\")\n",
        "\n",
        "ds = pd.DataFrame(ds['train'])\n",
        "ds.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 - Indicando produtos a um amigo\n",
        "\n",
        "> Dado o título do produto e a review, devemos verificar se o modelo consegue prever corretamente se o autor do comentário indicaria ou não o produto\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uA7A6RaxpAmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds[['review_title', 'review_text']].head()"
      ],
      "metadata": {
        "id": "IylYaeTMpb51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = ds.sample(n=1, random_state=21)\n",
        "print('Titulo: ', example['review_title'].to_list()[0])\n",
        "print()\n",
        "print('Review: ', example['review_text'].to_list()[0])"
      ],
      "metadata": {
        "id": "D0FEzvqqP_5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "      {\"role\": \"user\", \"content\": \"\"\"\n",
        "        Você é uma assistente que vai receber uma revisão de um produto e deve dizer se o autor da review recomenda ou não o produto para um amigo\n",
        "        Titulo: BOM\n",
        "        Review: SÓ DEMOROU A CHEGAR, MAS JÁ COMPREI OUTRAS COISA E NÃO TIVE PROBLEMAS, FOI A PRIMEIRA VEZ QUE ATRASA, DE RESTO TUDO BEM.\n",
        "        \"\"\"},\n",
        "]\n",
        "output = pipe(messages,temperature=0.01)[0][\"generated_text\"][1]['content']\n",
        "print('Saida do modelo: ', output)"
      ],
      "metadata": {
        "id": "6aKHb7jnz5Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "      {\"role\": \"user\", \"content\": \"\"\"\n",
        "        Você é uma assistente que vai receber uma revisão de um produto e deve dizer se o autor da review recomenda ou não o produto para um amigo.\n",
        "        Gere uma explicação passo a passo.\n",
        "        Titulo: BOM\n",
        "        Review: SÓ DEMOROU A CHEGAR, MAS JÁ COMPREI OUTRAS COISA E NÃO TIVE PROBLEMAS, FOI A PRIMEIRA VEZ QUE ATRASA, DE RESTO TUDO BEM.\n",
        "        \"\"\"},\n",
        "]\n",
        "output = pipe(messages,temperature=0.01)[0][\"generated_text\"][1]['content']\n",
        "print('Saida do modelo: ', output)"
      ],
      "metadata": {
        "id": "LSSMsJVIT0-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: Gerando descrição automática do produto\n",
        "> Dado o nome do produto e sua categoria, devemos instruir o modelo a gerar uma descrição automática do produto.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uk3LYD182q22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Dado o nome do produto abaixo, gere uma descrição sucinta para atrair a venda desse produto.\n",
        "                                  Titulo: Fone De Ouvido Eb-201bk Preto Lite; Categoria: Áudio\"\"\"},\n",
        "]\n",
        "output = pipe(messages,temperature=0.01)[0][\"generated_text\"][1]['content']\n",
        "output"
      ],
      "metadata": {
        "id": "W7bm5uyi5o4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Dado o nome do produto abaixo, gere uma descrição sucinta para atrair a venda desse produto para o seguinte perfil de compradores:\n",
        "                                  Jovens de 15 a 20 anos que gostam de jogar video-game;\n",
        "                                  Titulo: Fone De Ouvido Eb-201bk Preto Lite; Categoria: Áudio\"\"\"},\n",
        "]\n",
        "output = pipe(messages,temperature=0.01)[0][\"generated_text\"][1]['content']\n",
        "output"
      ],
      "metadata": {
        "id": "i62D9rUG7VRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Dado o nome do produto abaixo, gere uma descrição sucinta para atrair a venda desse produto para o seguinte perfil de compradores:\n",
        "                                  Adultos de mais de 40 anos a 60 anos;\n",
        "                                  Titulo: Fone De Ouvido Eb-201bk Preto Lite; Categoria: Áudio\"\"\"},\n",
        "]\n",
        "output = pipe(messages,temperature=0.01)[0][\"generated_text\"][1]['content']\n",
        "output"
      ],
      "metadata": {
        "id": "sPNNjICe28Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Gerando o resumo de revisões de um produto\n",
        "Dado as top-3 avaliações aleátorias de um determinado produto, devemos instruir ao modelo a gerar um resumo das avaliações.\n",
        "\n",
        "Essa prática é semelhante ao empregado em RAG (Retrieval-Augmented Generation), isto é, o modelo utiliza de fontes externas (infos de um DB, busca da internet, documentos internos) para compor a saída final.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yMvtaiIH5OOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(ds['product_name'].to_list()).most_common(3)\n"
      ],
      "metadata": {
        "id": "H4-3C2m537Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prod_name = 'Smartphone Motorola Moto G 5S Dual Chip Android 7.1.1 Nougat Tela 5.2\" Snapdragon 430 32GB 4G Câmera 16MP - Platinum'\n",
        "filter_prod = ds[ds['product_name']==prod_name].sample(3 , random_state=15)\n",
        "filter_prod"
      ],
      "metadata": {
        "id": "8wfxuTTo_6U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "      {\"role\": \"user\", \"content\": \"\"\"\n",
        "        Dada as reviews de um produto abaixo, gere um único resumo geral.\n",
        "        Review 1:\n",
        "        Adorei o produto\n",
        "        Como faço para fazer seguro do celular ? quero fazer e como proceder\n",
        "\n",
        "        Review 2:\n",
        "        Excelente custo e benefício\n",
        "        Ótimo aparelho. Surpreende na qualidade da mantagem, acabamento e material aplicado na carcaça. Mas dá umas travada de vez em quando. Não é o aparelho mais rápido do mundo mas tem excelente desempenho. Até o momento não tivemos nem um problema\n",
        "\n",
        "        Review 3:\n",
        "        Moto g5S\n",
        "        Compra e entrega ocorreram conforme esperado. Estou plenamente satisfeito com a compra.\"\"\"},\n",
        "]\n",
        "output = pipe(messages,temperature=0.01)[0][\"generated_text\"][1]['content']\n",
        "print('Saida do modelo: ', output)"
      ],
      "metadata": {
        "id": "nG53CONqUirq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}